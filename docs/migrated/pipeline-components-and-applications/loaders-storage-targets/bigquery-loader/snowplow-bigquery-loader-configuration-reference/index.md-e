---
title: "Configuration reference"
date: "2021-10-07"
sidebar_position: 0
---

This is a complete list of the options that can be configured in the Snowplow BigQuery Loader HOCON config file. The [example configs in github](https://github.com/snowplow-incubator/snowplow-bigquery-loader/tree/master/config) show how to prepare an input file.

## Required options

<table><tbody><tr><td>projectId</td><td>Required. The GCP project in which all required Pub/Sub, BigQuery and GCS resources are hosted, eg <code>my-project</code>.</td></tr><tr><td>loader.input.subscription</td><td>Required. Enriched events subscription consumed by Loader and StreamLoader, eg <code>enriched-sub</code>.</td></tr><tr><td>loader.output.good.datasetId</td><td>Required. Specify the dataset to which the events table belongs, eg <code>snowplow</code>.</td></tr><tr><td>loader.output.good.tableId</td><td>Required. The name of the events table, eg <code>events</code>.</td></tr><tr><td>loader.output.bad.topic</td><td>Required. The name of the topic where bad rows will be written, eg <code>bad-topic</code>.</td></tr><tr><td>loader.output.types.topic</td><td>Required. The name of the topic where observed types will be written, eg <code>types-topic</code>.</td></tr><tr><td>loader.output.failedInserts.topic</td><td>Required. The name of the topic where failed inserts will be written, eg <code>failed-inserts-topic</code>.</td></tr><tr><td>mutator.input.subscription</td><td>Required. A subscription on the <code>loader.output.types.topic</code>, eg <code>types-sub</code>.</td></tr><tr><td>mutator.output.good.*</td><td>Required. Equivalent to <code>loader.output.good.*</code>. Can be specified in detail or as <code>${loader.output.good}</code>.</td></tr><tr><td>repeater.input.subscription</td><td>Required. Failed inserts subscription consumed by Repeater. Must be attached to the <code>loader.output.failedInserts.topic</code>, eg <code>failed-inserts-sub</code>.</td></tr><tr><td>repeater.output.good.*</td><td>Required. Equivalent to <code>loader.output.good.*</code>. Can be specified in detail or as <code>${loader.output.good}</code>.</td></tr><tr><td>repeater.output.deadLetters.bucket</td><td>Required. Failed inserts that repeatedly fail to be inserted into BigQuery are stored on GCS in this bucket, eg <code>gs://dead-letter-bucket</code>.</td></tr><tr><td>monitoring.*</td><td>Optional. See below for details.<br><br><em>Note</em>: This was a required setting in 1.0.0. Can be left blank, ie <code>{}</code>, to disable this functionality in that version.</td></tr></tbody></table>

## Monitoring options

<table><tbody><tr><td>monitoring.statsd.*</td><td>Optional. If set up, metrics will be emitted from StreamLoader and Repeater using the <a href="https://github.com/statsd/statsd">StatsD</a> protocol.</td></tr><tr><td>monitoring.statsd.hostname</td><td>Optional, eg <code>statsd.acme.gl</code>.</td></tr><tr><td>monitoring.statsd.port</td><td>Optional, eg <code>1024</code>.</td></tr><tr><td>monitoring.statsd.tags</td><td>Optional. You can use env vars, eg <code>{"worker": ${HOST}}</code>.</td></tr><tr><td>monitoring.statsd.period</td><td>Optional, eg <code>10 sec</code>.</td></tr><tr><td>monitoring.statsd.prefix</td><td>Optional, eg <code>snowplow.monitoring</code>.</td></tr><tr><td>monitoring.dropwizard.*</td><td>Optional. If set up, metrics will be emitted from Loader using the <a href="https://www.dropwizard.io/en/latest/">Dropwizard</a> protocol.</td></tr><tr><td>monitoring.dropwizard.period</td><td>Optional, eg <code>10000 ms</code>.</td></tr><tr><td>monitoring.stdout.*</td><td>Optional. If set up, metrics will be logged to <code>stdout</code> at <code>INFO</code> level.</td></tr><tr><td>monitoring.sentry</td><td>Optional. If set up, errors will be sent to a <a href="https://sentry.io/">Sentry</a> endpoint.</td></tr></tbody></table>

## Advanced options

The defaults should be good for the overwhelming majority of deployments and hopefully you should never need to change these.

<table><tbody><tr><td>loader.loadMode.*</td><td>BigQuery supports two loading APIs:<br>- <a href="https://cloud.google.com/bigquery/streaming-data-into-bigquery">Streaming inserts API</a><br>- <a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs">Load jobs API</a><br><br><br>This setting configures which one will be used.<br><br>StreamLoader only supports the Streaming inserts API. Loader supports both but using the Load jobs API has experimental status.</td></tr><tr><td>loader.loadMode.type</td><td>Defaults to <code>StreamingInserts</code>. The only other possible option is <code>FileLoads</code>.</td></tr><tr><td>loader.loadMode.retry</td><td>Defaults to <code>false</code>. Specifies if failed inserts should be retried infinitely or sent straight to the&nbsp;<code>failedInserts</code>&nbsp;topic. When set to <code>true</code>, if a row cannot be inserted, it will be re-tried indefinitely, which can throttle the whole load. In that case a restart might be required. This setting is only supported by the Streaming inserts API.</td></tr><tr><td>loader.loadMode.frequency</td><td>Defaults to <code>null</code>. Specifies how often the load job should be performed, in seconds. Unlike the near-real-time&nbsp;Streaming inserts&nbsp;API, load jobs are more batch-oriented. This setting is only supported by the Load jobs API. An example value is <code>60000</code>.</td></tr><tr><td>loader.consumerSettings.*</td><td>Settings for the <code>PubsubGoogleConsumer</code> object in the StreamLoader code. For more details see <a href="https://github.com/permutive/fs2-google-pubsub/blob/v0.15.0/fs2-google-pubsub-grpc/src/main/scala/com/permutive/pubsub/consumer/grpc/PubsubGoogleConsumerConfig.scala">here</a>.</td></tr><tr><td>loader.sinkSettings.good.*</td><td>Settings for the good sink value in the StreamLoader code. For more details see <a href="https://github.com/snowplow-incubator/snowplow-bigquery-loader/blob/master/modules/streamloader/src/main/scala/com/snowplowanalytics/snowplow/storage/bigquery/streamloader/Resources.scala#L143-L175">here</a>. For recommended number of records in each request, see <a href="https://cloud.google.com/bigquery/quotas#streaming_inserts">here</a>. For the HTTP request size limit, see <a href="https://cloud.google.com/bigquery/quotas#streaminginserts">here</a>.</td></tr><tr><td>loader.sinkSettings.bad.*</td><td>Settings for the bad sink value in the StreamLoader code. For more details see <a href="https://github.com/snowplow-incubator/snowplow-bigquery-loader/blob/master/modules/streamloader/src/main/scala/com/snowplowanalytics/snowplow/storage/bigquery/streamloader/Resources.scala#L107-L124">here</a>.</td></tr><tr><td>loader.sinkSettings.types.*</td><td>Settings for the type sink value in the StreamLoader code. For more details see <a href="https://github.com/snowplow-incubator/snowplow-bigquery-loader/blob/master/modules/streamloader/src/main/scala/com/snowplowanalytics/snowplow/storage/bigquery/streamloader/Resources.scala#L126-L141">here</a>.</td></tr><tr><td>loader.sinkSettings.failedInserts.*</td><td>Settings for the failed insert sink value in the StreamLoader code. For more details see <a href="https://github.com/snowplow-incubator/snowplow-bigquery-loader/blob/master/modules/streamloader/src/main/scala/com/snowplowanalytics/snowplow/storage/bigquery/streamloader/Resources.scala#L88-L103">here</a>.</td></tr><tr><td>loader.retrySettings.*</td><td>Retry settings for the BigQuery client. For more details see <a href="https://cloud.google.com/java/docs/reference/gax/latest/com.google.api.gax.retrying.RetrySettings">here</a>.</td></tr><tr><td>loader.terminationTimeout</td><td>Defaults to <code>1 minute</code>. Specifies how long to wait before terminating the application after receiving <code>SIGINT</code>. This is meant to allow time for all events in-flight to be processed and acknowledged before exiting.</td></tr></tbody></table>

## Config parser hints

These settings only exist as hints to the config parsing library we use, so that the configuration can be represented as Scala code. They each only have one possible value and should never be changed.

<table><tbody><tr><td>loader.input.type</td><td><code>PubSub</code></td></tr><tr><td>loader.output.good.type</td><td><code>BigQuery</code></td></tr><tr><td>loader.output.bad.type</td><td><code>PubSub</code></td></tr><tr><td>loader.output.types.type</td><td><code>PubSub</code></td></tr><tr><td>loader.output.failedInserts.type</td><td><code>PubSub</code></td></tr><tr><td>loader.retrySettings.type</td><td><code>BigQueryRetrySettings</code></td></tr><tr><td>mutator.input.type</td><td><code>PubSub</code></td></tr><tr><td>repeater.input.type</td><td><code>PubSub</code></td></tr><tr><td>repeater.output.deadLetters.type</td><td><code>Gcs</code></td></tr></tbody></table>
